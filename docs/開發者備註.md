# 開發者備註

這是一個實驗性套件。本文件記錄目前的限制、設計決策及重要技術說明。
> **注意**：本專案在 LLM 輔助下開發。請在正式使用前審查並驗證所有程式碼。

版本 0.1.0 已完成測試。`examples/` 和 `testing_bits/` 中的所有腳本皆已驗證可正常運作。
`testing_bits/` 中的音訊檔案未包含在儲存庫中。請自行提供測試用音訊檔案。

---

## 目前限制

### 檔案大小
- 支援的最大音訊檔案大小：**2000 MB**
- 較大的檔案可能導致記憶體問題或處理時間過長
- 建議在轉錄前將大型檔案分割

### 語言支援
- 已實作語言自動偵測，但本套件**僅針對中文和英文進行優化**
- 其他語言（日文、韓文等）可能可以使用，但未經測試
- 支援中英混合內容

### 中文輸出
- **預設為繁體中文** — Whisper 輸出會透過 OpenCC 自動轉換
- 簡體中文使用者需要修改 `transcriber.py`（將 `OpenCC("s2t")` 改為 `OpenCC("t2s")` 或移除轉換）

### LLM 後處理
- 需要在本機執行 Ollama
- 長篇轉錄稿會分段處理（預設：500 字元）
- LLM 品質因模型而異 — 請參閱下方建議模型
- 處理時間隨轉錄稿長度增加

### GPU 支援
- GPU 加速需要 CUDA 12.x 和 cuDNN 9.x
- 若 GPU 不可用，將退回使用 CPU（速度顯著較慢）
- `large-v3` 模型需要約 10GB VRAM

---

## 設計決策

### 為何使用本機 LLM（Ollama）？
本套件設計用於轉錄亞福專有、機密的會議內容。使用本機 LLM 可確保敏感資料不會離開您的電腦。

### 為何預設繁體中文？
本套件為台灣使用情境開發。Whisper 傾向輸出簡體中文，因此在 `transcriber.py` 中自動套用 OpenCC 轉換。

### 為何使用分段處理？
本機 LLM（7B-9B 參數）在處理長上下文視窗時效能不佳。分段處理可改善超過約 500 字元的轉錄稿的速度和輸出品質。

### 為何分離轉錄和後處理？
- 轉錄（Whisper）是確定性的且快速
- 後處理（Ollama）是選用的且較慢
- 只需要原始轉錄稿的使用者可跳過 LLM 處理

---

## 建議的 Ollama 模型

| 語言 | 模型 | 備註 |
|--------------|---------------|-------------|
| 中文（繁體）  | `yi:9b`       | 中文預設模型 |
| 英文         | `llama3.1:8b` | 英文預設模型 |
| 通用 / 其他  | `qwen2.5:7b`   | 備用模型    |

---

## 測試備註

- 測試用音訊檔案建議在 5 分鐘以內，以便快速迭代
- 使用 `model_size="base"` 或 `"small"` 可加快測試速度（準確度較低）
- GPU 測試：`device="cuda"` — 若 CUDA 未正確設定將會報錯

---

## 已知的待改善項目

- LLM 有時會加入不必要的開場白（「以下是整理後的文字：」），即使提示詞已有指示
- 分段邊界偶爾可能影響上下文連貫性
- SRT 匯出使用原始片段時間軸 — 清理後的文字可能無法與時間戳完美對齊